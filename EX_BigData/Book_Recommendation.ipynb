{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° **Summary:**  \n",
    "There are way too many books to read even in a lifetime, so there is a question which books to recommend in the first place. In this project, I build an explicit-based recommendation engine to predict ratings on unread books, based on the previous explicit ratings. It's a collaborative filtering recommendation engine, that works based on similar user preferences. \n",
    "\n",
    "üî¢ **Dataset:**    \n",
    "Book ratings from individual Goodreads users.\n",
    "\n",
    "\n",
    "üß∞ü§ñ **Tools and techniques:**  \n",
    "The recommendation system works on Spark, which is a popular framework for Big Data analysis.  \n",
    "I use an Alternating Least Squares model (ALS) with a non-negative matrix factorization algorithm to factorize the user-book matrix. Then I can approximate the original matrix and predict the blank cells (user haven't read this book).\n",
    "\n",
    "\n",
    "üîß **Possible improvements:**  \n",
    "1. Use the latent features to extract unobservable features that imply some kind of user preferences - f.eg movies with Tom Hank as an actor.  \n",
    "2. Add more information from other .csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëç I hope this notebook will be helpful to you.   \n",
    "üí¨ I will appreciate any comments, thoughts, ideas and questions in the comment section.  \n",
    "üí° Constructive criticism will be appreciated.  \n",
    "\n",
    "üéâ Have fun! üòÅ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåç Notebook published: 19-10-09  \n",
    "üîß Last update: 19-10-09   \n",
    "üë®‚Äçüíª By Artur G√≥rlicki "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='table_of_contents'></a>\n",
    "# Table of Contents:\n",
    "\n",
    "0. <a href='#section_s0'>SETTINGS</a>\n",
    "\n",
    "1. <a href='#section_s1'>INTRODUCTION</a>\n",
    "2. <a href='#section_s2'>DATA PREPERATION</a>  \n",
    "3. <a href='#section_s3'>EXPLORATORY DATA ANALYSIS (EDA)</a>\n",
    "4. <a href='#section_s4'>MACHINE LEARNING (ML) </a>  \n",
    "4.1 <a href='#section_s41'>Cross Validation Pipeline</a>  \n",
    "4.2 <a href='#section_s42'>Alternating Least Squares Model (ALS) </a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#table_of_contents'>Back to Table of Contents</a>  \n",
    "#  \n",
    "<a id='section_s0'></a>\n",
    "# 0. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\r\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215.7MB 73kB/s \r\n",
      "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\r\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 204kB 37.6MB/s \r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216131250 sha256=d2b1bb085cdb88ed2918a4d7e85f05b875cca0db16dd7b8a023ddfbb8bd7f590\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: py4j, pyspark\r\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.4\r\n"
     ]
    }
   ],
   "source": [
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# PySpark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "from pyspark.sql.functions import col, min, max, avg, lit\n",
    "\n",
    "# Machine Learning (ML)\n",
    "from pyspark.ml.recommendation import ALS # Alternating Least Squares model\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator # Cross-Validation\n",
    "from pyspark.ml.evaluation import RegressionEvaluator # Performance metric\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "\n",
    "from matplotlib import rcParams\n",
    "sns.set(context='notebook', style='whitegrid', rc={'figure.figsize': (18,4)})\n",
    "rcParams['figure.figsize'] = 18,4\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Setting random seed for reproducability\n",
    "SEED = 23\n",
    "np.random.seed = SEED\n",
    "np.random.set_state = SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[*] appName=Book-Recommendation>\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName = \"Book-Recommendation\")\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f16d84f7f60>\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.Builder().getOrCreate()\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#table_of_contents'>Back to Table of Contents</a>  \n",
    "#  \n",
    "<a id='section_s1'></a>\n",
    "# 1. INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#table_of_contents'>Back to Table of Contents</a>  \n",
    "#  \n",
    "<a id='section_s2'></a>\n",
    "# 2. DATA PREPERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Read csv into Spark DataFrame\n",
    "ratings = spark.read.csv('../input/goodbooks-10k/ratings.csv',\n",
    "                         header = True,\n",
    "                         inferSchema=True)\n",
    "print(type(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Read csv\n",
    "to_read = spark.read.csv('../input/goodbooks-10k/to_read.csv',\n",
    "                         header = True,\n",
    "                         inferSchema=True)\n",
    "print(type(to_read))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is quite big, so for the purpose of showing the technique I will extract a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9837\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings.sample(withReplacement = False, \n",
    "                         fraction = 0.01, # 1% of observation\n",
    "                         seed = 2019)\n",
    "print(ratings.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use .printSchema() to see the datatypes of the ratings dataset\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the columns to the proper data types\n",
    "ratings = ratings.select(ratings.user_id,\n",
    "                         ratings.book_id,\n",
    "                         ratings.rating.cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- book_id: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call .printSchema() again to confirm the columns are now in the correct format\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#table_of_contents'>Back to Table of Contents</a>  \n",
    "#  \n",
    "<a id='section_s3'></a>\n",
    "# 3. EXPLORATORY DATA ANALYSIS (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|book_id|rating|\n",
      "+-------+-------+------+\n",
      "|  30681|      1|   5.0|\n",
      "|  14546|      2|   5.0|\n",
      "|   5885|      3|   4.0|\n",
      "|  17228|      8|   4.0|\n",
      "|  49288|      8|   5.0|\n",
      "+-------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# First few rows of data\n",
    "print(ratings.show(n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the ratio bewteen empty cells/all cells in matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratings dataframe is  99.98% empty.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = ratings.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct Id's\n",
    "num_users = ratings.select(\"user_id\").distinct().count()\n",
    "num_items = ratings.select(\"book_id\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of items\n",
    "denominator = num_users * num_items\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "sparsity = (1.0 - (numerator * 1.0)/ denominator) * 100\n",
    "print(\"The ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically empty! But its not a problem for ALS as we will see soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GroupBy and Filter Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|user_id|count|\n",
      "+-------+-----+\n",
      "|  38082|    6|\n",
      "|  17073|    6|\n",
      "|  18857|    6|\n",
      "|  27934|    5|\n",
      "|  13991|    5|\n",
      "|  12734|    5|\n",
      "|  21820|    5|\n",
      "|   8340|    5|\n",
      "|   8959|    5|\n",
      "|  26629|    5|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group data by user_id, count ratings\n",
    "(ratings.groupBy(\"user_id\")\n",
    "    .count()\n",
    "    .filter(\"`count` > 1\")\n",
    "    .sort(col(\"count\").desc())\n",
    "    .show(n = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|book_id|count|\n",
      "+-------+-----+\n",
      "|   4245|    6|\n",
      "|   9119|    6|\n",
      "|   4230|    6|\n",
      "|   3917|    6|\n",
      "|   8822|    5|\n",
      "|   1580|    5|\n",
      "|   9088|    5|\n",
      "|   4317|    5|\n",
      "|   4515|    5|\n",
      "|   1546|    5|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group data by book_id, count ratings\n",
    "(ratings.groupBy(\"book_id\")\n",
    "    .count()\n",
    "    .filter(\"`count` > 1\")\n",
    "    .sort(col(\"count\").desc())\n",
    "    .show(n = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Min num ratings for items\n",
    "print(\"Item with the fewest ratings: \")\n",
    "ratings.groupBy(\"book_id\").count().select(min(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg num ratings per item: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|1.5701516360734238|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avg num ratings per item\n",
    "print(\"Avg num ratings per item: \")\n",
    "ratings.groupBy(\"book_id\").count().select(avg(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User with the fewest ratings: \n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Min num ratings for user\n",
    "print(\"User with the fewest ratings: \")\n",
    "ratings.groupBy(\"user_id\").count().select(min(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg num ratings per user: \n",
      "+------------------+\n",
      "|        avg(count)|\n",
      "+------------------+\n",
      "|1.2592165898617511|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Avg num ratings per users\n",
    "print(\"Avg num ratings per user: \")\n",
    "ratings.groupBy(\"user_id\").count().select(avg(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#table_of_contents'>Back to Table of Contents</a>  \n",
    "#  \n",
    "<a id='section_s4'></a>\n",
    "# 4. MACHINE LEARNING (ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the ALS model to factorize the sparse user-book matrix into two separate matrixes. When we reverse this process and multiply two factor matrixes, we will get an approximation for each cell in the initial matrix, also those cells that were blank. Every cell will be filled with numbers. Those values that were present in the initial matrix, will act as a label for the training process. The model will try to minimize the difference between actual values and values from the multiplication of factor matrixes. In some sense, as a byproduct, it predicts the empty values.\n",
    "\n",
    "The factorization algorithm will be non-negative matrix factorization (NMF or NNMF), because we want to have only positive values. In goodreads book rating system ratings are only positive (0-5). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#table_of_contents'>Back to Table of Contents</a>  \n",
    "#  \n",
    "<a id='section_s41'></a>\n",
    "### 4.1. Cross Validation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Generic ALS model - without hyperparameters\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"book_id\", ratingCol=\"rating\", \n",
    "          nonnegative = True, # Non negative matrix factorization\n",
    "          coldStartStrategy = \"drop\", # What to do if user do not appear in train and test set\n",
    "          implicitPrefs = False) # Explicit preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.recommendation.ALS"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that a model called \"als\" was created\n",
    "type(als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Create test and train set\n",
    "(train, test) = ratings.randomSplit([0.8, 0.2], \n",
    "                                    seed = 1234)\n",
    "print(type(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hyperparameters and their respective values to param_grid\n",
    "param_grid = ParamGridBuilder() \\\n",
    "            .addGrid(als.rank, [10, 50, 100]) \\\n",
    "            .addGrid(als.maxIter, [5, 50, 100]) \\\n",
    "            .addGrid(als.regParam, [.01, .05, .1]) \\\n",
    "            .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to minimize the Root Mean Square Error (RMSE), so the difference between predicted rating and actual rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models to be tested:  27\n"
     ]
    }
   ],
   "source": [
    "# Define evaluator as RMSE\n",
    "evaluator = RegressionEvaluator(metricName = \"rmse\", \n",
    "                                labelCol = \"rating\", \n",
    "                                predictionCol = \"prediction\")\n",
    "# Print length of evaluator\n",
    "print (\"Num models to be tested: \", len(param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build cross validation using CrossValidator\n",
    "cv = CrossValidator(estimator = als, \n",
    "                    estimatorParamMaps = param_grid, \n",
    "                    evaluator = evaluator, \n",
    "                    numFolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossValidator_822218f59a45\n"
     ]
    }
   ],
   "source": [
    "# Confirm cv was built\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#table_of_contents'>Back to Table of Contents</a>  \n",
    "#  \n",
    "<a id='section_s42'></a>\n",
    "### 4.2. Alternating Least Squares Model (ALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit generic model to the 'train' dataset\n",
    "als_mod = als.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = als_mod.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+----------+\n",
      "|user_id|book_id|rating|prediction|\n",
      "+-------+-------+------+----------+\n",
      "|  33864|   1580|   3.0| 1.9183098|\n",
      "|  14841|   1645|   5.0| 2.0209856|\n",
      "|   2749|   6336|   4.0|  3.371828|\n",
      "|  17328|   8638|   5.0|0.36690933|\n",
      "|  41460|   4158|   3.0| 1.3361363|\n",
      "|  26400|   1303|   5.0| 1.1609883|\n",
      "|  15007|    808|   5.0| 1.6413031|\n",
      "|  41616|    458|   3.0|  2.994131|\n",
      "|  32204|   5578|   4.0|  1.913218|\n",
      "|  11285|   3028|   3.0|  2.065584|\n",
      "+-------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the predictions \n",
    "test_pred.show(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7316151044723673\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the RMSE of test_predictions\n",
    "print(evaluator.evaluate(test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark value. On average we are above or below the actual rating of 2.7. This is huge taking into account that rating is in range 0-5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validated model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there is a error when I try to fit the model to the data. I will try to correct it soon. For now the best model is generic als model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit cross validator to the 'train' dataset\n",
    "# cv_mod = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract best model from the cv model above\n",
    "# best_model = cv_mod.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best_model\n",
    "# print(type(best_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Complete the code below to extract the ALS model parameters\n",
    "# print(\"**Best Model**\")\n",
    "\n",
    "# # Print \"Rank\"\n",
    "# print(\"  Rank:\", best_model.getRank())\n",
    "\n",
    "# # Print \"MaxIter\"\n",
    "# print(\"  MaxIter:\", best_model.getMaxIter())\n",
    "\n",
    "# # Print \"RegParam\"\n",
    "# print(\"  RegParam:\", best_model.getRegParam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = als_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = best_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+----------+\n",
      "|user_id|book_id|rating|prediction|\n",
      "+-------+-------+------+----------+\n",
      "|  33864|   1580|   3.0| 1.9183098|\n",
      "|  14841|   1645|   5.0| 2.0209856|\n",
      "|   2749|   6336|   4.0|  3.371828|\n",
      "|  17328|   8638|   5.0|0.36690933|\n",
      "|  41460|   4158|   3.0| 1.3361363|\n",
      "|  26400|   1303|   5.0| 1.1609883|\n",
      "|  15007|    808|   5.0| 1.6413031|\n",
      "|  41616|    458|   3.0|  2.994131|\n",
      "|  32204|   5578|   4.0|  1.913218|\n",
      "|  11285|   3028|   3.0|  2.065584|\n",
      "+-------+-------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE:  2.7316151044723673\n"
     ]
    }
   ],
   "source": [
    "# View the predictions \n",
    "test_predictions.show(n = 10)\n",
    "\n",
    "# Calculate and print the RMSE of test_predictions\n",
    "print (\"RMSE: \", evaluator.evaluate(test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE is quite big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Evaluation and Output Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate n recommendations for all users\n",
    "ALS_recommendations = best_model.recommendForAllUsers(numItems = 10) # n - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will generate 10 recommendations for all users. It may also generate recommendations for books that the user has already read. I will filter them out later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|     recommendations|\n",
      "+-------+--------------------+\n",
      "|   4900|[[2820, 4.9217324...|\n",
      "|   6620|[[4911, 4.555248]...|\n",
      "|   7240|[[9464, 4.9488525...|\n",
      "|  21700|[[7350, 4.9506803...|\n",
      "|  27760|[[7622, 2.6407099...|\n",
      "|  32460|[[7404, 4.3317385...|\n",
      "|  48510|[[4454, 5.725117]...|\n",
      "|  18051|[[3970, 4.921773]...|\n",
      "|  38311|[[8339, 4.9450903...|\n",
      "|  40011|[[5456, 5.0649285...|\n",
      "+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ALS_recommendations.show(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform the output to user_id | book_id | predicted rating shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary table\n",
    "ALS_recommendations.registerTempTable(\"ALS_recs_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+\n",
      "|user_id|book_id|prediction|\n",
      "+-------+-------+----------+\n",
      "|   4900|   2820| 4.9217324|\n",
      "|   4900|   6486| 4.6845436|\n",
      "|   4900|   1440| 4.5387926|\n",
      "|   4900|   5492|  4.516373|\n",
      "|   4900|    534|  4.511571|\n",
      "|   4900|   6285|  4.491678|\n",
      "|   4900|   8907|  4.403657|\n",
      "|   4900|   2041|  4.391653|\n",
      "|   4900|   4126| 4.3852353|\n",
      "|   4900|   6175|    4.3761|\n",
      "|   6620|   4911|  4.555248|\n",
      "|   6620|   1744|  4.470581|\n",
      "|   6620|   1025|  4.362337|\n",
      "|   6620|   4508| 4.3102474|\n",
      "|   6620|   6920| 4.2992077|\n",
      "|   6620|   3542|  4.296758|\n",
      "|   6620|   9501| 4.2871203|\n",
      "|   6620|   8591| 4.2662153|\n",
      "|   6620|   9768|  4.259452|\n",
      "|   6620|   4012|  4.242892|\n",
      "+-------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_recs = spark.sql(\"\"\"SELECT user_id,\n",
    "                            movieIds_and_ratings.book_id AS book_id,\n",
    "                            movieIds_and_ratings.rating AS prediction\n",
    "                        FROM ALS_recs_temp\n",
    "                        LATERAL VIEW explode(recommendations) exploded_table\n",
    "                            AS movieIds_and_ratings\"\"\")\n",
    "clean_recs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check, which book wasn't read by the user I will join the table with the actual rating and filter out those where there is a rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+------+\n",
      "|user_id|book_id|prediction|rating|\n",
      "+-------+-------+----------+------+\n",
      "|   4900|   6486| 4.6845436|  null|\n",
      "|   4900|   1440| 4.5387926|  null|\n",
      "|   4900|   5492|  4.516373|  null|\n",
      "|   4900|    534|  4.511571|  null|\n",
      "|   4900|   6285|  4.491678|  null|\n",
      "|   4900|   8907|  4.403657|  null|\n",
      "|   4900|   2041|  4.391653|  null|\n",
      "|   4900|   4126| 4.3852353|  null|\n",
      "|   4900|   6175|    4.3761|  null|\n",
      "|   6620|   4911|  4.555248|  null|\n",
      "|   6620|   1744|  4.470581|  null|\n",
      "|   6620|   1025|  4.362337|  null|\n",
      "|   6620|   4508| 4.3102474|  null|\n",
      "|   6620|   6920| 4.2992077|  null|\n",
      "|   6620|   3542|  4.296758|  null|\n",
      "|   6620|   9501| 4.2871203|  null|\n",
      "|   6620|   8591| 4.2662153|  null|\n",
      "|   6620|   9768|  4.259452|  null|\n",
      "|   6620|   4012|  4.242892|  null|\n",
      "|   7240|   8063|  4.673035|  null|\n",
      "+-------+-------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recommendations for unread books\n",
    "(clean_recs.join(ratings, [\"user_id\", \"book_id\"], \"left\")\n",
    "    .filter(ratings.rating.isNull()).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_books = (clean_recs.join(ratings, [\"user_id\", \"book_id\"], \"left\")\n",
    "    .filter(ratings.rating.isNull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63255\n"
     ]
    }
   ],
   "source": [
    "print(new_books.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will joint the table with to_read table. This table stores information which books user marked as \"I would like to read it\". This might indicate that he is likely to rate them high, because he has chosen them in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+------+-------+\n",
      "|user_id|book_id|prediction|rating|to_read|\n",
      "+-------+-------+----------+------+-------+\n",
      "|    513|   1078| 3.8150978|  null|   null|\n",
      "|    927|    739| 4.9066334|  null|   null|\n",
      "|   1121|   9797| 5.3307767|  null|   null|\n",
      "|   1175|   2021| 4.9970274|  null|   null|\n",
      "|   1576|   8864| 3.2155378|  null|   null|\n",
      "|   1799|   2268| 3.9579291|  null|   null|\n",
      "|   1866|   6303|  4.394198|  null|   null|\n",
      "|   1916|   3124| 4.2498875|  null|   null|\n",
      "|   2163|   3668| 5.1476393|  null|   null|\n",
      "|   2373|   4054| 4.7827616|  null|   null|\n",
      "|   2382|   2638| 4.5336623|  null|   null|\n",
      "|   2432|   6312|  4.377811|  null|   null|\n",
      "|   2477|   5109| 2.1214325|  null|   null|\n",
      "|   2485|   5237| 4.0008345|  null|   null|\n",
      "|   2660|   1257| 4.0051045|  null|   null|\n",
      "|   3050|   8505| 4.3424144|  null|   null|\n",
      "|   3306|     95| 4.5352917|  null|   null|\n",
      "|   3548|   1919| 4.4738526|  null|   null|\n",
      "|   3962|   3234|  4.467758|  null|   null|\n",
      "|   3971|   7402| 3.6912634|  null|   null|\n",
      "+-------+-------+----------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "recommendations = new_books.join(to_read.withColumn('to_read', lit(1)), \n",
    "                              on = [\"user_id\", \"book_id\"], \n",
    "                              how = \"left\")\n",
    "print(recommendations.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|to_read|count|\n",
      "+-------+-----+\n",
      "|   null|63166|\n",
      "|      1|   89|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(recommendations\n",
    "     .groupby('to_read')\n",
    "     .count()\n",
    "     .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only several dozen books, that users marked \"I want to read\".  \n",
    "Let's see what is the predicted rating for those books. The hypothesis is that on average it will be high, because user wants to read them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+-------+\n",
      "|user_id|book_id|prediction|to_read|\n",
      "+-------+-------+----------+-------+\n",
      "|  41946|   5810| 3.5906856|      1|\n",
      "|  49101|   3241|  2.087709|      1|\n",
      "|  12139|   7683| 4.4270315|      1|\n",
      "|  40670|   2702| 4.4551253|      1|\n",
      "|  25812|   4695|  4.103054|      1|\n",
      "|  32860|   2244|  4.399159|      1|\n",
      "|  11468|   7402|  3.953835|      1|\n",
      "|  20452|    329|  4.757228|      1|\n",
      "|  40110|    276| 4.5199947|      1|\n",
      "|  38214|    319|  4.705698|      1|\n",
      "|   4293|   2954| 4.1656017|      1|\n",
      "|  44401|   5072|  4.462099|      1|\n",
      "|   2962|   1325| 2.4017355|      1|\n",
      "|  22846|   2114| 3.2482762|      1|\n",
      "|  28530|   8039| 4.5299163|      1|\n",
      "|  40851|   9797| 4.6195726|      1|\n",
      "|  36987|    476| 3.9769363|      1|\n",
      "|  24962|    150|       0.0|      1|\n",
      "|  29464|   9587| 4.2431493|      1|\n",
      "|  43131|    883| 4.5905147|      1|\n",
      "+-------+-------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(recommendations\n",
    "     .filter(recommendations.to_read.isNotNull())\n",
    "     .select(['user_id', 'book_id', 'prediction','to_read'])\n",
    "     .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+-------+\n",
      "|user_id|book_id|prediction|to_read|\n",
      "+-------+-------+----------+-------+\n",
      "|  41946|   5810| 3.5906856|      1|\n",
      "|  49101|   3241|  2.087709|      1|\n",
      "|  12139|   7683| 4.4270315|      1|\n",
      "|  40670|   2702| 4.4551253|      1|\n",
      "|  25812|   4695|  4.103054|      1|\n",
      "+-------+-------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_read_recs = (recommendations\n",
    "     .filter(recommendations.to_read.isNotNull())\n",
    "     .select(['user_id', 'book_id', 'prediction','to_read']))\n",
    "to_read_recs.show(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|pred_trunc|count|\n",
      "+----------+-----+\n",
      "|         0|    2|\n",
      "|         1|    2|\n",
      "|         2|    5|\n",
      "|         3|   18|\n",
      "|         4|   52|\n",
      "|         5|    9|\n",
      "|         7|    1|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(to_read_recs\n",
    "     .withColumn('pred_trunc', to_read_recs.prediction.substr(1,1))\n",
    "     .groupby('pred_trunc')\n",
    "     .count()\n",
    "     .sort('pred_trunc')\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the times people choose to read books, that are predicted to be 4 and 5, so it seems that the recommendation engine works quite good in recommending books, that people might like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to ALS, we have a huge pool of books that we can recommend to specific user. We can filter the unread books with highest ratings and propose them to the user.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëç I hope this notebook was helpful to you.  \n",
    "üí¨ I will appreciate any comments, thoughts, ideas and questions in the comment section.  \n",
    "üí° Constructive criticism will be appreciated.  \n",
    "\t\t\t\n",
    "üéâ Thanks! üòÅ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö Learning resources:  \n",
    "[Collaborative Filtering-Apache.org](https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html)  \n",
    "[Building Recommendation Engines with PySpark!-DataCamp](https://www.datacamp.com/courses/recommendation-engines-in-pyspark) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîù  <a href='#table_of_contents'>Back to Table of Contents</a> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
